\section{Related Work}

GPT-2 \cite{radford2019language}, introduced by OpenAI, is a large-scale transformer-based language model that demonstrated significant improvements in natural language understanding and generation tasks. By leveraging a massive dataset and unsupervised learning, GPT-2 is capable of generating coherent and contextually relevant text, making it a foundational model for subsequent advancements in natural language processing.

The RecipeNLG dataset \cite{bien2020recipenlg} is a large-scale collection of over 2 million cooking recipes, designed specifically for natural language generation tasks. It provides structured information including ingredients, instructions, and titles, enabling research on text generation, recipe understanding, and related applications. The dataset's diversity and size make it a valuable resource for training and evaluating language models in the culinary domain.